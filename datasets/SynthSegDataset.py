import torch
import torch.utils.data as data
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import os
import shutil
import PIL.Image as Image
import random

class ToLabel:
    "Convert label from 0-1 to 0-255 as uint8"

    def __call__(self, tensor):
        tensor = (tensor*255).type(torch.long).squeeze()
        return tensor

class SynthSegDataset(data.Dataset):
    """Loads a dataset generated by SynthDegGenerator.
    
    Inputs: 
        datadir (str): Root directory of the dataset,
        transform : Data transforms to be applied to the images.
        target_transforms: Data transforms to be applied to the labels.
    
    Output
        image: The image after transforms have been applied.
        label: The label after transforms have been applied.
    """

    def __init__(self, datadir, transform=None, target_transform=None):
        self.root = datadir
        self.transform = transform
        self.target_transform = target_transform

        self.imagePath = os.path.join(self.root, 'images')
        self.labelPath = os.path.join(self.root, 'labels')
        self.filenamesPath = os.path.join(self.root, 'filenames.txt')
 
        with open(self.filenamesPath) as f:
            self.ids = f.readlines()
        self.ids = [x.strip('\n') for x in self.ids]

    def __getitem__(self, index):
        img_id = self.ids[index]
        image = Image.open(os.path.join(self.imagePath, img_id))
        label = Image.open(os.path.join(self.labelPath, img_id))

        if self.transform is not None:
            img = self.transform(image)

        if self.target_transform is not None:
            label = self.target_transform(label)
        
        return img, label

    def __len__(self):
        return len(self.ids)

class SynthSegGenerator:
    """ Generates a synthetic dataset meant to demonstrate the effect of 
    a network's receptive field in semantic segmentation. Each image contains a single object
    from one of two classes. Each object is randomly generated from a uniform distribution of 
    lengths, widths, and classes.

    Input:
        canvasSize (tuple/list): Height and width of the image used to draw objects.
        lengths (tuple): Minimum and maximum object length.
        widths (tuple) : Minimum and Maximum object width.
        transforms (optional): Data transforms to apply to the image after the object has been placed.
        seed (int): Seed for the RNG used to create objects.
        
    """
    def __init__(self, canvasSize, lengths, widths, transforms=None, seed=None):
        
        self.canvasSize = canvasSize
        self.minLength = lengths[0]
        self.maxLength = lengths[1]
        self.minWidth  = widths[0]
        self.maxWidth  = widths[1]
        self.transforms = transforms

        #PARAMS
        self.seed = seed
        self.nClasses = 3
        self.bgVal = 112
        self.bgClass = 0
        self.objVal = 128

        # Set RNG seed
        if self.seed is not None:
            np.random.seed(self.seed)
            random.seed(self.seed)

    def _generateImage(self):

        # Create empty image and matching label
        image = np.zeros(self.canvasSize, dtype=np.uint8)
        label = np.zeros(self.canvasSize, dtype=np.uint8)
        image.fill(self.bgVal)
        label.fill(self.bgClass)

        # Create an object
        length = np.random.randint(self.minLength, high = self.maxLength)
        width = np.random.randint(self.minWidth, high = self.maxWidth)
        target = np.random.randint(1, high=self.nClasses + 1)

        # Find the top left corner
        x = self.canvasSize[0]//2 - length//2
        y = self.canvasSize[1]//2 - width//2

        # Place the object
        image[y:(y+width), x:(x+length)] = self.objVal
        label[y:(y+width), x:(x+length)] = target

        # Place the markers at either end of the object
        if self.nClasses == 3:

            if target == 1:
                # If the object is class 1, it will have white markers on both ends.
                image[y:(y+width), x:(x+width)] = 255 # Left marker
                image[y:(y+width), (x+length-width):(x+length)] = 255 # Right marker

            elif target == 2:
                # If the object is class 2, it will have a near-black markers on one end.
                # 0 is not used because torchvision transforms pad with 0 and we want to replace
                # any padding with the background color later.

                image[y:(y+width), x:(x+width)] = 255 # Left marker
                image[y:(y+width), (x+length-width):(x+length)] = 1 # Right marker

            elif target == 3:
                # If the object is class 3, it will have black markers on both ends.
                image[y:(y+width), x:(x+width)] = 1 # Left marker
                image[y:(y+width), (x+length-width):(x+length)] = 1 # Right marker
            else:
                raise Exception('Target value out of range')
        else:
            raise NotImplementedError()

        # Concat the image and label to form an example, we add a dummy channel
        # because PIL expects a third channel. This is a bit of a hack to
        # ensure the same transforms are applied to the image and the label
        dummy = label
        ex = np.stack((image, label, dummy), axis=-1)

        # Apply transforms
        if self.transforms is not None:
            ex = self.transforms(ex)

            # Replace any padding with backgroud color and return to np array
            ex = ex*255
            ex[0, ex[0]==0] = self.bgVal
            ex = ex.numpy().astype(np.uint8)

        image = ex[0]
        label = ex[1]

        return image, label

    def __call__(self, N, datadir, overwrite=True, updateRate=100):


        # Check if dir exists, if not make it
        if os.path.isdir(datadir):
            if overwrite:
                print('Overwriting %s' % datadir)
                shutil.rmtree(datadir)
            else:
                raise Exception('Datadir already exists and overwiting is turned off: %s' % datadir)
        else:
            print('Creating Output Directory: %s' % datadir)

        imagePath = os.path.join(datadir, 'images')
        labelPath = os.path.join(datadir, 'labels')
        os.makedirs(imagePath)
        os.makedirs(labelPath)

        # Generate images
        print('Generating %d examples...' % N)
        filenames = []
        for i in range(N):

            if ((i+1)%updateRate == 0) and not (i==0):
                print('%6d' % (i+1))

            image, label = self._generateImage()

            # Save image and label
            img = Image.fromarray(image)
            lab = Image.fromarray(label)

            filename = '%06d.png' % i
            img.save(os.path.join(imagePath, filename))
            lab.save(os.path.join(labelPath, filename))
            filenames.append(filename)

        # Save list of filenames for dataloading later
        fileListPath = os.path.join(datadir, 'filenames.txt')
        print('Saving Filelist to %s' % fileListPath)
        with open(fileListPath, 'w') as f:
            for item in filenames:
                f.write("%s\n" % item)

if __name__ == '__main__':

    data_transforms = transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomRotation(180),
        #transforms.RandomHorizontalFlip(),
        # transforms.CenterCrop((128, 256)),
        transforms.ToTensor()
    ])

    # Create dataset generator
    # train_gen = SynthSegGenerator((280,280), (96, 128), (8, 16), transforms=data_transforms, seed=123)
    train_gen = SynthSegGenerator((64,64), (32, 60), (2, 3), transforms=data_transforms, seed=123)

    # Generate images
    train_gen(64, '/scratch/klensink/data/synthseg_noise/train/')
    train_gen(64, '/scratch/klensink/data/synthseg_noise/val/')
    # val_gen(16, '/scratch/klensink/data/synthseg/val/')
